# ğŸ›’ E-commerce Price Monitoring & Product Data Scraper

## ğŸ“Œ Project Overview
This project is a professional Python-based web scraping solution for collecting and monitoring product data from e-commerce websites. It extracts key details such as product names, prices, vendors, and availability, then delivers clean, structured datasets in CSV, Excel, and JSON formats.  

The project highlights a client-ready, ethical approach to web scraping with outputs designed for business analysis, automation, and reporting.  

> *Note: This project was developed and tested on live e-commerce data. For portfolio purposes, only sanitized sample outputs are included to ensure legal and ethical compliance.*

---

## âš™ï¸ Features  
- **Accurate Product Data** â€“ Titles, prices, vendors, availability, SKUs, and links.  
- **Pagination Handling** â€“ Automatically collects data across all product pages.  
- **Clean, Structured Outputs** â€“ Deduplicated and normalized datasets.  
- **Multiple Export Formats**:  
  - `products.csv` â€“ Clean product dataset  
  - `variants.csv` â€“ Variant-level details  
  - `products.xlsx` â€“ Excel with multiple sheets (Products & Variants)  
  - `products.json` â€“ Raw structured data  
- **Ethical & Professional Practices** â€“ Custom User-Agent, robots.txt compliance, and polite rate limiting.  

---

## ğŸ“‚ Project Structure  

press_scraper/  
â”‚  
â”œâ”€â”€ scraper/  
â”‚   â”œâ”€â”€ fetch_products_api.py     # Fetches product data with pagination (API-based)  
â”‚   â”œâ”€â”€ parse_products.py         # Cleans and structures raw product data  
â”‚   â”œâ”€â”€ export_products.py        # Exports datasets to CSV, JSON, Excel  
â”‚   â”œâ”€â”€ rate_limiter.py           # Polite scraping with basic rate limiting  
â”‚   â”œâ”€â”€ robots_checker.py         # Checks robots.txt compliance  
â”‚  
â”œâ”€â”€ outputs/                      # Sample sanitized outputs (no real URLs)  
â”‚   â”œâ”€â”€ products.json  
â”‚   â”œâ”€â”€ products.csv  
â”‚   â”œâ”€â”€ products_clean.csv  
â”‚   â”œâ”€â”€ products.xlsx  
â”‚  
â”œâ”€â”€ screenshots/                  # Portfolio screenshots  
â”‚   â”œâ”€â”€ run_and_structure.png     # Combined terminal run + project structure  
â”‚   â”œâ”€â”€ excel_output.png          # Sanitized Excel output sample  
â”‚   â”œâ”€â”€ code_snippet.png          # Key code excerpt (sanitized)  
â”‚  
â”œâ”€â”€ README.md  
â””â”€â”€ requirements.txt  

---


---


---

## ğŸ“Š Sample Output (Sanitized)  

> *Note: Dataset samples (CSV, JSON, Excel) are fully sanitized for legal and ethical reasons. The terminal screenshot shows a real scraper run on live data, but no raw client data is shared.*  

### Example CSV (`products.csv`)  

| id         | title            | handle             | vendor      | price_min | price_max | url                               |
|------------|-----------------|------------------|------------|-----------|-----------|----------------------------------|
| 1000000001 | Sample Product A | sample-product-a | Demo Store | 19.99     | 19.99     | https://www.example.com/product-a |
| 1000000002 | Sample Product B | sample-product-b | Demo Store | 24.99     | 29.99     | https://www.example.com/product-b |

### Example JSON (`products.json`)  

```json
[
  {
    "id": 1000000001,
    "title": "Sample Product A",
    "handle": "sample-product-a",
    "vendor": "Demo Store",
    "price_min": 19.99,
    "price_max": 19.99,
    "url": "https://www.example.com/product-a"
  },
  {
    "id": 1000000002,
    "title": "Sample Product B",
    "handle": "sample-product-b",
    "vendor": "Demo Store",
    "price_min": 24.99,
    "price_max": 29.99,
    "url": "https://www.example.com/product-b"
  }
]


ğŸš€ How It Works

1. **Activate the virtual environment**
   Windows (PowerShell): & venv\Scripts\Activate.ps1
   Linux / MacOS: source venv/bin/activate
   ![Run and structure](screenshots/run_and_structure.png)  
   *ğŸ“¸ Screenshot: Running the scraper project and viewing folder structure*  

2. **Run the scraper to fetch products**  
   python -m scraper.fetch_products_api  
   ![Code snippet](screenshots/code_snippet.png)  
   *ğŸ“¸ Screenshot: Example code snippet from `fetch_products_api.py`*  

3. **Parse and clean the data**  
   python -m scraper.parse_products  

4. **Export the datasets**  
   python -m scraper.export_products  
   ![Excel output](screenshots/excel_output.png)  
   *ğŸ“¸ Screenshot: Cleaned product dataset exported to Excel*  

All processed files are saved inside the `outputs/` folder:  
- `products.csv` â€“ Clean dataset  
- `products.xlsx` â€“ Excel report (Products & Variants sheets)  
- `products.json` â€“ Raw structured data  

---

## âš™ï¸ Installation & Usage  

1. Clone the Repository  
   git clone https://github.com/Ek-Coder-Tech/press_scraper.git  
   cd press_scraper  

2. Create a Virtual Environment  
   - Windows: python -m venv venv && venv\Scripts\activate  
   - Linux/Mac: python3 -m venv venv && source venv/bin/activate  

3. Install Dependencies  
   pip install -r requirements.txt  

4. Run the Workflow  
   # Step 1: Fetch product data  
   python -m scraper.fetch_products_api  

   # Step 2: Parse & clean product data  
   python -m scraper.parse_products  

   # Step 3: Export to CSV, Excel, JSON  
   python -m scraper.export_products  

The final structured outputs will be available in the `outputs/` directory.  

---

## âš™ï¸ Technologies Used  
- Python 3.11 â€“ Core language  
- Requests â€“ Fetch product data via API  
- JSON & CSV modules â€“ Structured outputs  
- OpenPyXL â€“ Excel reporting  

---

## ğŸ¯ Use Cases  
This scraper can be adapted for:  
- ğŸ“Š Price Monitoring â€“ Track competitor pricing trends  
- ğŸ›’ E-Commerce Catalogs â€“ Feed structured data into ERP/CRM systems  
- ğŸ“‘ Market Research â€“ Collect clean datasets for analysis  
- âš™ï¸ Workflow Automation â€“ Integrate into pipelines or dashboards  

---

## ğŸ’¼ How Clients Benefit  
- ğŸ“Š Price Tracking & Market Research â€“ Monitor competitorsâ€™ pricing and availability  
- ğŸ›’ Catalog Management â€“ Automate updates to product listings  
- âš™ï¸ Business Automation â€“ Connect clean data with ERP/CRM workflows  
- ğŸ“‘ Reporting & Analytics â€“ Generate dashboards and insights directly from structured data  

---

## ğŸ”® Next Steps / Future Improvements  

This project demonstrates a strong foundation for professional e-commerce scraping. Future enhancements can expand its business value and technical robustness:  

- ğŸŒ **Multi-Site Support** â€“ Unify data collection across multiple e-commerce platforms.  
- ğŸ“¦ **Variant & Inventory Tracking** â€“ Monitor stock levels, sizes, and color variations.  
- ğŸ“ˆ **Historical Price Tracking** â€“ Record and analyze pricing trends over time.  
- ğŸ”” **Automated Alerts** â€“ Notify via email/Slack when products restock or prices change.  
- ğŸ—„ï¸ **Database Integration** â€“ Store results in SQL/NoSQL databases for scalability.  
- â˜ï¸ **Cloud Deployment** â€“ Run scheduled scrapers using Docker, GitHub Actions, or cloud services.  
- ğŸ“Š **Analytics & Dashboards** â€“ Feed clean data into BI tools (Power BI, Tableau, Metabase) for decision-making.  
- ğŸ” **Advanced Rate Limiting & Proxies** â€“ Strengthen compliance and resilience against request blocks.  

---

## âš–ï¸ Legal & Professional Standards  

This project follows ethical scraping practices:  
- âœ… Respects `robots.txt` directives  
- âœ… Uses polite rate limiting  
- âœ… No login, personal, or private data is collected  
- âœ… Portfolio/demo use only â€” not intended for unauthorized commercial deployment  

*Important: Always review a websiteâ€™s terms of service before deploying scrapers in production.*  

---

## ğŸ“„ License / Disclaimer  

This repository is provided **for educational and portfolio purposes only**.  
- No live client or proprietary data is included.  
- Example outputs are fully sanitized.  
- The author assumes no liability for misuse of this project.  

Licensed under the MIT License â€” you are free to use and adapt with attribution.  

---

## ğŸ™Œ Acknowledgments / Author Info  

Developed by **Eric â€” Python Automation & Web Developer**  
- ğŸ”— GitHub: [https://github.com/Ek-Coder-Tech]  
- ğŸ’¼ Upwork: [https://www.upwork.com/freelancers/~012558bab6232e8e65]  
- ğŸ¯ Fiverr: [https://www.fiverr.com/sellers/eric_mutisya/edit]  

Special thanks to the Python open-source community for the libraries and tools that made this project possible.  